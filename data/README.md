# Human Perceptions of Fairness in Algorithmic Decision Making: A Case Study of Criminal Risk Prediction

This repository provides a Python implementation of our code, which generates the results presented in our WWW 18 paper [1].


### Demo

By running demo.py, you can generate the results presented in our WWW 18 paper [1].


### Data Files

1. data/fr_data.csv
   * Contains the data gathered in Pilot Survey 1: Fairness Judgments and Their Latent Reasons (described in Section 3.1.2 of [1])
   * The description of the data file can be found in data/fr_description.txt

2. data/ip_data.csv
   * Contains the data gathered in Pilot Survey 2: Latent Properties of Features (described in Section 3.1.3 of [1])
   * The description of the data file can be found in data/ip_description.txt

3. data/pt_AMT_data.csv
   * Contains the data gathered in the Main Survey: Fairness Judgments and Latent Properties of Features (described in Section 3.1.4 of [1]), for the AMT sample
   * The description of the data file can be found in data/pt_description.txt

4. data/pt_SSI_data.csv
   * Contains the data gathered in the Main Survey: Fairness Judgments and Latent Properties of Features (described in Section 3.1.4 of [1]), for the SSI sample
   * The description of the data file can be found in data/pt_description.txt


### References

[1] Nina Grgi&#263;-Hla&#269;a, Elissa M. Redmiles, Krishna P. Gummadi, and Adrian Weller. 
	Human Perceptions of Fairness in Algorithmic Decision Making: A Case Study of Criminal Risk Prediction
	WWW (2018).
